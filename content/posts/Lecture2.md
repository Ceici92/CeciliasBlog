---
title: "Lecture 2"
date: 2020-10-04T19:55:25+02:00
draft: false
featured_image: "https://github.com/Ceici92/HugoBlog/blob/master/docs/images/Lecture2/merrie_morris.jpg?raw=true"
---

Hello everyone !

Today, I learned more about the researches around Human Computer Interaction, here is a little mark of what I learned.

# HCI Researcher : Meredith Ringel Morris

![alt Text](https://github.com/Ceici92/HugoBlog/blob/master/docs/images/Lecture2/merrie_morris.jpg?raw=true "");

I chose to talk about the researcher Meredith Ringel Morris. 
I found her thanks to the Microsoft site, where there is an article about one of her papers. 
I liked the fact that it was targeting the accessibility of HCI for everyone.

So I looked into her Microsoft profile.
She founded the lab's Ability Research Group, that conduct research about the tech-challenges to create more inclusive technologies. 
She is known as the founder of collaborative eb search, with her system SearchTogether.
Furthermore, she is known for her contributions to surface computing and gesture design, her papers introduced cooperative gestures and identity-aware widgets. 
More recently, she became a leader in accessibility, particularly in the field of social media, and accessible communication technologies.


Besides, she served as the general chair for ACM's CSCW conference, and as Technical Program chair of several conferences.
She wrote more than 100 peer-reviewed research articles, invented 20 U/S. patents, and influenced many of Microsoft's products.


Mrs. Morris recently wrote in collaboration the paper : Sense and Accessibility: Understanding People with Physical Disabilities' Experiences with Sensing Systems.

In this paper, she once again studies the sensing technologies that mediate digital experience, in order to make them appropriate for people with physical disabilities.
She and the other authors (Shaun Kane and Anhong Guo), conducted a survey with 40 adults with physical disabilities, and their experiences with sensing systems, such as : motion sensors, biometric sensors, speech input, and touch and gesture systems.

The result of their survey identified multiple challenges : the premature timeouts, the device positioning being invisible to sensors, the infidelity of sensors to a range of motion, the variability of the users' abilities over time, the difficulty to set up sensing systems, the biometric failures, the security vulnerabilities, and the data validation problems.
The participants' answers also showed the reaction of the users to the limitations of the sensor systems.
They tend to solicit assistance, design adaptations, avoid certain classes of technologies, or even abandon devices.
This paper will help future researchers to understand the divides coming from the emerging technologies, and it points out to them how to undermine those inequalities through designing and deploying more inclusive sensing systems.


# The Ultimate Display form Evan E. Sutherland

In this paper, Evan Sutherland points out the interesting 1960s' displays, which will be developed in the future. On top of that, he even predicts new displays that we use today. 

First, he reminds us about the importance of a display: understand digital computers as we understand the laws in a physical world. 

Then, from the displays used in his area, he guesses the ones that will be mainly used in the future : the keyboards, the "area filling" ability, the stylus and its drag and drop ability, the knobs and the joysticks.

He even successes in predicting human computer interactions that did not exist in the 1960s. For example, he figures out that not only the arm and the hand can be useful, but also all the rest of our body. This reflexion is what led us to the Kinect technology 50 years after.

Besides, he also predicts the modelling of objects that do not have realistic properties, or the modelling of the ones that we do not fully understand. 

At the end, the author talks about an ability that our computers still do not have: create matter or the sensation of it. Today, we have 3D printers that can create a new object of matter. Furthermore, we have virtual reality that can visually create a world in front of the player eyes. 

However, the 3D printers are still not fast enough to create a chair in front of the user as fast as he imagines it, and there is still no democratised haptic feedback in virtual reality that could give the player the sensation to sit on a real chair for example.

On another part, Evan Sutherland dreams of the control of computer through vision. Current technologies enable us to identify where the user is looking, it is for example used for user detection to unblock a computer, or to identify a user. However, even if some companies took the risk to use the eyes' glance as "mouse", it is uncomfortable for the player. Thus, even if current technologies enable it, it may be let aside in our future.



# Input Devices and Interaction Paradigms

![alt Text](https://github.com/Ceici92/HugoBlog/blob/master/docs/images/Lecture2/Ring.jpg?raw=true "");

The Ring by Logbar is a wearable input device aim to control payment, text, or any other parameter of another device, through hand gestures. The product was showed for the first time at the Consumer Electronics Show in Las Vegas in 2015.
A button in the side of the ring enables the user to signal the harware that it will make a geture, and with an application on your phone you can configure the gestures you want to do. 

This 3D User Interface from is a failure. The first reason could be that most of its functionalities are only for simple things, such as : turning off the lights, writing messages (which seems faster with our phones), make payments, move a 3D modelidation, etc...
All those things can already be easily done with existing inputs, while with a big ring it could become exhausting. 
When we look into users' review online, it validates this idea. Indeed, the ring is uncomfortable due to its large size and its weight, so it is quite useless to augment the volume of our phone with it.

A second reason of the Logbar's input failure is its inprecision. In theory, you have to learn a specific way tu write, so that the ring can understand more easily what you are typing.
For this funcitonality it could already be frustrating, and it raises doubts about the precision when doing other gestures. 
The users' review once again shows us that the precision is really low. Indeed, the succes rate of a gesture is between 5 and 10%. This rate, has been confirmed by the ring support team. 

The users review also criticize the software. No gesture is pre-configured even for the basics functionalities, the application has to be open on the phone for the ring to be used, and even some of the functionalities showed in the set up video (such as turning on the tv) are not available.


Sources : 
https://www.infoworld.com/article/2872529/goodbye-keyboard-the-future-of-input-devices-is-almost-here.html#slide6
https://www.youtube.com/watch?v=nBUWxROnqwA
